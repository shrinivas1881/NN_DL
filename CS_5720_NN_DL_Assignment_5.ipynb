{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cz9-yq40SuR"
      },
      "source": [
        "Lesson Overview:\n",
        "\n",
        "In this lesson, we are going to discuss types of ANNs and Recurrent Neural Network.\n",
        "\n",
        "Use Case Description:\n",
        "\n",
        "1. Sentiment Analysis on the Twitter dataset\n",
        "Programming elements:\n",
        "1. Basics of LSTM\n",
        "2. Types of RNN\n",
        "3. Use case: Sentiment Analysis on the Twitter data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ii3Npmm70Re-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # Importing pandas for data processing\n",
        "from keras.preprocessing.text import Tokenizer  # Importing Tokenizer for text preprocessing\n",
        "from keras.utils import pad_sequences  # Importing pad_sequences for sequence padding\n",
        "from keras.models import Sequential  # Importing Sequential for building a sequential model\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D  # Importing various layers for the LSTM model\n",
        "from matplotlib import pyplot  # Importing matplotlib for plotting\n",
        "from sklearn.model_selection import train_test_split , GridSearchCV  # Importing train_test_split for data splitting and grid search cv\n",
        "from keras.utils.np_utils import to_categorical  # Importing to_categorical for one-hot encoding\n",
        "import re  # Importing re for regular expression operations\n",
        "from sklearn.preprocessing import LabelEncoder  # Importing LabelEncoder for label encoding\n",
        "import numpy as np # Importing Numpy\n",
        "from keras.wrappers.scikit_learn import KerasClassifier  # Importing kerasclassfier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6cTY1QQ408JY"
      },
      "outputs": [],
      "source": [
        "# Read the data from 'Sentiment.csv' and keep only the 'text' and 'sentiment' columns\n",
        "data = pd.read_csv('Sentiment.csv')\n",
        "data = data[['text', 'sentiment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E167DV1J1BwV"
      },
      "outputs": [],
      "source": [
        "# Convert text to lowercase and remove special characters using regular expressions\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nt_QGd6Q1F9K"
      },
      "outputs": [],
      "source": [
        "# Replace 'rt' (retweet) with a space in the text\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rB5YsAJ71LNU"
      },
      "outputs": [],
      "source": [
        "max_fatures = 2000  # Set the maximum number of unique words to 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')  # Create a tokenizer with the specified max_fatures\n",
        "tokenizer.fit_on_texts(data['text'].values)  # Fit the tokenizer on the text data\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)  # Convert text to sequences using the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "05N0UVAM1Val"
      },
      "outputs": [],
      "source": [
        "X = pad_sequences(X)  # Pad the sequences to make them of equal length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8EDKJQdK1aH8"
      },
      "outputs": [],
      "source": [
        "embed_dim = 128  # Set the embedding dimension to 128\n",
        "lstm_out = 196  # Set the LSTM output dimension to 196"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JBRjIYMY1csY"
      },
      "outputs": [],
      "source": [
        "# Function to create the LSTM model\n",
        "def createmodel():\n",
        "    model = Sequential()  # Create a sequential model\n",
        "    model.add(Embedding(max_fatures, embed_dim, input_length=X.shape[1]))  # Add an Embedding layer\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))  # Add an LSTM layer with dropout\n",
        "    model.add(Dense(3, activation='softmax'))  # Add a Dense output layer with softmax activation\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Compile the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VhlBwjjf1gSX"
      },
      "outputs": [],
      "source": [
        "# Encode the 'sentiment' labels using LabelEncoder and convert them into one-hot encoded vectors\n",
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaotpeMo1kcm",
        "outputId": "1ec08a9d-a945-4b86-8928-7cdc864c6e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "291/291 - 61s - loss: 0.8265 - accuracy: 0.6482 - 61s/epoch - 208ms/step\n",
            "Epoch 2/7\n",
            "291/291 - 41s - loss: 0.6794 - accuracy: 0.7114 - 41s/epoch - 140ms/step\n",
            "Epoch 3/7\n",
            "291/291 - 39s - loss: 0.6121 - accuracy: 0.7471 - 39s/epoch - 134ms/step\n",
            "Epoch 4/7\n",
            "291/291 - 38s - loss: 0.5711 - accuracy: 0.7651 - 38s/epoch - 131ms/step\n",
            "Epoch 5/7\n",
            "291/291 - 38s - loss: 0.5233 - accuracy: 0.7839 - 38s/epoch - 131ms/step\n",
            "Epoch 6/7\n",
            "291/291 - 38s - loss: 0.4842 - accuracy: 0.8049 - 38s/epoch - 130ms/step\n",
            "Epoch 7/7\n",
            "291/291 - 37s - loss: 0.4427 - accuracy: 0.8206 - 37s/epoch - 129ms/step\n",
            "144/144 - 2s - loss: 0.9148 - accuracy: 0.6603 - 2s/epoch - 11ms/step\n",
            "0.9147756099700928\n",
            "0.6603320240974426\n",
            "['loss', 'accuracy']\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "batch_size = 32  # Set the batch size to 32\n",
        "model = createmodel()  # Create the LSTM model using the createmodel function\n",
        "model.fit(X_train, Y_train, epochs=7, batch_size=batch_size, verbose=2)  # Train the model for seven epoch\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)  # Evaluate the model on the test set\n",
        "\n",
        "# Print the loss, accuracy, and metric names\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxVw0w910ysl"
      },
      "source": [
        "In class programming:\n",
        "1. Save the model and use the saved model to predict on new text data (ex, “A lot of good things are\n",
        "happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnZKSmm2db9",
        "outputId": "6cacf07b-8d5b-4dd0-faa4-ef28aa455eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 497ms/step\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "# After training the model (model.fit), save the model using model.save()\n",
        "model.save('sentiment_analysis_model.h5')\n",
        "\n",
        "# Later, load the model using keras.models.load_model()\n",
        "from keras.models import load_model\n",
        "loaded_model = load_model('sentiment_analysis_model.h5')\n",
        "\n",
        "# Now, you can use the loaded model to predict on new text data\n",
        "new_text = \"A lot of good things are happening. We are respected again throughout the world, and that's a great thing. @realDonaldTrump\"\n",
        "new_text = new_text.lower()\n",
        "new_text = re.sub('[^a-zA-z0-9\\s]', '', new_text)\n",
        "new_text_sequence = tokenizer.texts_to_sequences([new_text])\n",
        "new_text_padded = pad_sequences(new_text_sequence, maxlen=X.shape[1])\n",
        "\n",
        "# Predict the sentiment for the new text\n",
        "predictions = loaded_model.predict(new_text_padded)\n",
        "# Decoding the predictions as we have encoded the the sentiments\n",
        "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
        "predicted_sentiment = sentiment_labels[np.argmax(predictions)]\n",
        "print(\"Predicted Sentiment:\", predicted_sentiment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2QVv17-87_R"
      },
      "source": [
        "2. Apply GridSearchCV on the source code provided in the class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVzmJm4B4dxf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Function to create the LSTM model\n",
        "def createmodel(optimizer, weight_initializer, activation, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_fatures, embed_dim, input_length=X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
        "    model.add(Dense(3, activation=activation))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Wrap the Keras model using KerasClassifier\n",
        "model = KerasClassifier(build_fn=createmodel, verbose=0)\n",
        "\n",
        "# Define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'optimizer': ['adam', 'rmsprop'],\n",
        "    'weight_initializer': ['uniform', 'glorot_uniform'],\n",
        "    'activation': ['relu', 'sigmoid'],\n",
        "    'dropout_rate': [0.2, 0.3]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the best parameters and accuracy\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "best_model = grid_result.best_estimator_\n",
        "acc = best_model.score(X_test, Y_test)\n",
        "print(\"Test Accuracy: %.2f%%\" % (acc * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAPYUjFm2LMK",
        "outputId": "724c9f5b-ad94-4c8a-b95d-54e1d1a98795"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.669967 using {'activation': 'sigmoid', 'dropout_rate': 0.2, 'optimizer': 'adam', 'weight_initializer': 'uniform'}\n",
            "Test Accuracy: 67.26%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}